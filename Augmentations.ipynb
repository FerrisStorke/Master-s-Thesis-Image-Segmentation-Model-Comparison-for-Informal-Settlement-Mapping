{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuFKO_aTt-Dv"
   },
   "source": [
    "# Image Augmentations for Model Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPIx9C5MuHku"
   },
   "source": [
    "## 1. Imports and GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QPm_LSaC7FmC"
   },
   "outputs": [],
   "source": [
    "# Hide output of this cell\n",
    "%%capture\n",
    "\n",
    "# Install packages\n",
    "!pip install fastcore fastai --upgrade\n",
    "!pip install rasterio\n",
    "!pip install geopandas\n",
    "\n",
    "# Import packages\n",
    "from fastai.vision.all import *\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.io import imread, imsave\n",
    "import imageio\n",
    "from skimage.transform import rotate\n",
    "from skimage.util import random_noise\n",
    "import cv2\n",
    "import rasterio.features\n",
    "import shapely.geometry\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1K1nMSXuK9a"
   },
   "source": [
    "## 2. Define Required Functions and Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61FNZdbdn-ou",
    "outputId": "df0d328c-dbbe-46ff-f07f-ecd09728ae72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "def informal_pixels_from_file(file):\n",
    "  \"\"\"Calculate share of pixels in a mask that belong to informal settlements.\"\"\"\n",
    "  with rasterio.open(file, 'r') as mask:\n",
    "    mask = mask.read()\n",
    "    settlement_pixels = np.count_nonzero(mask == 255)\n",
    "    total_pixels = mask.size\n",
    "    settlement_share = settlement_pixels / total_pixels\n",
    "    return settlement_share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ALSNm2q8Jgr"
   },
   "source": [
    "## 2. Create Image Augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4cJZvRv8M94"
   },
   "source": [
    "### 2.1. Create undersampled training data to use as baseline for augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNoBKk-YmeUF"
   },
   "outputs": [],
   "source": [
    "# Set type of imagery, mask, and tiles to augment, as well as root directory\n",
    "imagery_type = \"aerial\"\n",
    "mask_type = \"buildings\"\n",
    "tile_type = \"512_512 stride\"\n",
    "path = Path(f\"/content/drive/MyDrive/Segmentation Data/{imagery_type}\")\n",
    "\n",
    "# Set paths to images and corresponding masks and retrieve a list of all masks\n",
    "dir_img = f'{path}/image_tiles/\"2019_10cm_RGB_BE_67\"/{tile_type}'\n",
    "dir_msk = f'{path}/{mask_type}_mask_tiles/\"2019_10cm_RGB_BE_67\"/{tile_type}'\n",
    "lbl_names = get_image_files(dir_msk)\n",
    "\n",
    "# Create a list of masks containing buildings\n",
    "building_share = []\n",
    "for fn in lbl_names:\n",
    "  building_share.append(informal_pixels_from_file(fn))\n",
    "index = 0\n",
    "building_tiles = []\n",
    "for mask in building_share:\n",
    "  if mask > 0:\n",
    "    building_tiles.append(index)\n",
    "  index += 1\n",
    "\n",
    "# Set paths for undersampled images and masks\n",
    "dir_img_augm = f'{path}/image_tiles/\"2019_10cm_RGB_BE_67\"/512_512 undersampled'\n",
    "dir_msk_augm = f'{path}/{mask_type}_mask_tiles/\"2019_10cm_RGB_BE_67\"/512_512 undersampled'\n",
    "\n",
    "# Loop through all masks containing buildings and copy them, as well as the corresponding image tiles to a new folder\n",
    "for tile in building_tiles:\n",
    "  shutil.copyfile(fnames[tile], f\"{dir_img_augm}/{str(fnames[index]).split('/')[-1]}\")\n",
    "  shutil.copyfile(lbl_names[tile], f\"{dir_msk_augm}/{str(lbl_names[index]).split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VnWV8_H8bN6"
   },
   "source": [
    "### 2.2. Create Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-H1mqcQalu5C",
    "outputId": "28498ba0-76d0-4a62-9d86-c3a9570716d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 207/207 [00:43<00:00,  4.72it/s]\n"
     ]
    }
   ],
   "source": [
    "## Retrieve a list of all image and mask tiles in the new undersampled folder and set path to final folder for augmented images and masks\n",
    "fnames = get_image_files(dir_img_augm)\n",
    "lbl_names = get_image_files(dir_msk_augm)\n",
    "root = '/content/drive/MyDrive/Segmentation Data/aerial/augmented/8'\n",
    "\n",
    "# Loop through both tested splits, folders for images and masks, and the train and validation folder\n",
    "for split in [0.05, 0.2]:\n",
    "  for tile in ['img', 'lbl']:\n",
    "    for folder in [\"train\", \"valid\"]:\n",
    "      # Create a variable with the directory to each of the new folders\n",
    "      local_dir = f'{root}/{i}/{tile}/{folder}'\n",
    "      # If they don't already exist, create the folders\n",
    "      if not os.path.exists(local_dir):\n",
    "          os.makedirs(local_dir)\n",
    "      # Randomly select 5% and 20% of images and masks\n",
    "      img_train, img_test, msk_train, msk_test = train_test_split(fnames, lbl_names, test_size = split, random_state = 42)\n",
    "\n",
    "      # Copy selected images and masks to the 'valid' folder (they will remain untouched)\n",
    "      for file in img_test:\n",
    "        shutil.copyfile(file, f\"{local_dir}/{str(file).split('/')[-1]}\")\n",
    "      for file in msk_test:\n",
    "        shutil.copyfile(file, f\"{local_dir}/{str(file).split('/')[-1]}\")\n",
    "\n",
    "      # Check whether there is a mask for each validation image\n",
    "      if len(img_train) != len(msk_train):\n",
    "        print(len(img_train), len(msk_train))\n",
    "\n",
    "      # Open images and masks and append them to two new lists\n",
    "      train_img = []\n",
    "      train_msk = []\n",
    "      \n",
    "      for img_path in img_train:\n",
    "        img = imread(img_path)\n",
    "        train_img.append(img)\n",
    "      for msk_path in msk_train:\n",
    "        msk = imread(msk_path)\n",
    "        train_msk.append(msk)\n",
    "\n",
    "      # Convert lists of read-in images and masks to Numpy arrays to speed up augmentations \n",
    "      train_img = np.array(train_img)\n",
    "      train_msk = np.array(train_msk)\n",
    "\n",
    "      ## Create augmentations\n",
    "      final_train_data = []\n",
    "      final_target_train = []\n",
    "\n",
    "      # Loop through all images and corresponding masks to be augmented and append them and their transformations to the two final lists\n",
    "      for i in tqdm(range(train_img.shape[0])):\n",
    "          final_train_data.append(train_img[i]) # original image\n",
    "          final_train_data.append(rotate(train_img[i], angle = 90)) # 90 degree flipped\n",
    "          final_train_data.append(np.fliplr(train_img[i])) # left-right flipped\n",
    "          final_train_data.append(np.flipud(train_img[i])) # up-down flipped\n",
    "          final_train_data.append(random_noise(train_img[i], var = 0.2**2)) # random noise added\n",
    "          final_train_data.append(np.fliplr(rotate(train_img[i], angle = 90))) # rotated and left-right flipped\n",
    "          final_train_data.append(np.flipud(rotate(train_img[i], angle = 90))) # rotated and up-down flipped\n",
    "\n",
    "          final_target_train.append(train_msk[i]) # original mask\n",
    "          final_target_train.append(rotate(train_msk[i], angle = 90)) # 90 degree flipped\n",
    "          final_target_train.append(np.fliplr(train_msk[i])) # left-right flipped\n",
    "          final_target_train.append(np.flipud(train_msk[i])) # up-down flipped\n",
    "          final_target_train.append(train_msk[i]) # use orignal mask since position of buildings has not changed\n",
    "          final_target_train.append(np.fliplr(rotate(train_msk[i], angle = 90))) # rotated and left-right flipped\n",
    "          final_target_train.append(np.flipud(rotate(train_msk[i], angle = 90))) # rotated and up-down flipped\n",
    "\n",
    "          index = 0\n",
    "          # Store each augmented image and mask in the final augmentation folder\n",
    "          for img in final_train_data:\n",
    "            imageio.imwrite(f'{dir_augm}/img/train/{index}.png', img*255.astype(np.uint8))\n",
    "            index += 1\n",
    "\n",
    "          index = 0\n",
    "          for msk in final_target_train:\n",
    "            imageio.imwrite(f'{dir_augm}/lbl/train/{index}.png', msk*255).astype(np.uint8))\n",
    "            index += 1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Augmentations",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
